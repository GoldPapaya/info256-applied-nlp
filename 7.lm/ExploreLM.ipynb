{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/info256-applied-nlp/blob/main/7.lm/ExploreLM.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5d423c6e",
      "metadata": {
        "id": "5d423c6e"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp25/blob/main/7.lm/ExploreLM.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "fcf7e7a1-39e7-4dc6-9450-769112d4c6b1",
      "metadata": {
        "id": "fcf7e7a1-39e7-4dc6-9450-769112d4c6b1"
      },
      "source": [
        "# Language modeling\n",
        "\n",
        "In this notebook, we will construct an n-gram language model, and use it to generate sequences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "b52b3a60",
      "metadata": {
        "id": "b52b3a60",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "46305731-3d0f-40e2-94e4-4ab11bad7825"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ],
      "source": [
        "import copy\n",
        "from collections import Counter\n",
        "\n",
        "import nltk\n",
        "import numpy as np\n",
        "from nltk import sent_tokenize, word_tokenize\n",
        "\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "33eb376a",
      "metadata": {
        "id": "33eb376a"
      },
      "outputs": [],
      "source": [
        "def read_file(filename):\n",
        "    sequences = []\n",
        "    with open(filename) as file:\n",
        "        data = file.read()\n",
        "        sents = sent_tokenize(data)\n",
        "        for sent in sents:\n",
        "            tokens = word_tokenize(sent)\n",
        "            sequences.append(tokens)\n",
        "    return sequences"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "_4P6ewmTfAo0",
      "metadata": {
        "id": "_4P6ewmTfAo0",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e8e8790a-e7a6-4655-ffbe-cebaad390eb9"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-10-02 23:45:34--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/1342_pride_and_prejudice.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 691804 (676K) [text/plain]\n",
            "Saving to: ‘1342_pride_and_prejudice.txt’\n",
            "\n",
            "\r          1342_prid   0%[                    ]       0  --.-KB/s               \r1342_pride_and_prej 100%[===================>] 675.59K  --.-KB/s    in 0.04s   \n",
            "\n",
            "2025-10-02 23:45:34 (15.7 MB/s) - ‘1342_pride_and_prejudice.txt’ saved [691804/691804]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/1342_pride_and_prejudice.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "feeb46f4",
      "metadata": {
        "id": "feeb46f4"
      },
      "outputs": [],
      "source": [
        "# Read data from file and tokenize them into sequences comprised of tokens.\n",
        "\n",
        "# Pride and Prejudice (Jane Austen)\n",
        "sequences = read_file(\"1342_pride_and_prejudice.txt\")\n",
        "\n",
        "max_sequences = 10000"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "214dbd04",
      "metadata": {
        "id": "214dbd04"
      },
      "outputs": [],
      "source": [
        "class NgramModel():\n",
        "\n",
        "    def __init__(self, sequences, order):\n",
        "\n",
        "        # For this exercise we're going to encode the LM as a sparse dictionary (trading less storage for more compute)\n",
        "        # We'll store the LM as a dictionary with the conditioning context as keys; each value is a\n",
        "        # Counter object that keeps track of the number of times we see a word following that context.\n",
        "        self.counts = {}\n",
        "\n",
        "        # Markov order (order 1 = conditioning on previous 1 word; order 2 = previous 2 words, etc.)\n",
        "        self.order = order\n",
        "\n",
        "        vocab = {\"[END]\": 0}\n",
        "\n",
        "        for s_idx, tokens in enumerate(sequences):\n",
        "            # We'll add [START] and [END] tokens to encode the beginning/end of sentences\n",
        "            tokens = [\"[START]\"] * order + tokens + [\"[END]\"]\n",
        "\n",
        "            if s_idx == 0:\n",
        "                print(tokens)\n",
        "\n",
        "            for i in range(order, len(tokens)):\n",
        "                context = \" \".join(tokens[i - order:i])\n",
        "                word = tokens[i]\n",
        "\n",
        "                if word not in vocab:\n",
        "                    vocab[word] = len(vocab)\n",
        "\n",
        "                # For just the first sentence, print the conditioning context + word\n",
        "                if s_idx == 0:\n",
        "                    print(\"Context: %s Next: %s\" % (context.ljust(50), word))\n",
        "\n",
        "                if context not in self.counts:\n",
        "                    self.counts[context] = Counter()\n",
        "                self.counts[context][word] += 1\n",
        "\n",
        "\n",
        "\n",
        "    def sample(self, context):\n",
        "        total = sum(self.counts[context].values())\n",
        "\n",
        "        dist = []\n",
        "        vocab = []\n",
        "\n",
        "        # Create a probability distribution for each conditioning context, over the vocab that we've observed it with.\n",
        "        for idx, word in enumerate(self.counts[context]):\n",
        "            prob = self.counts[context][word]/total\n",
        "            dist.append(prob)\n",
        "            vocab.append(word)\n",
        "\n",
        "        index = np.argmax(np.random.multinomial(1, pvals=dist))\n",
        "        return vocab[index]\n",
        "\n",
        "    def generate_sequence(self, keep_ends=True):\n",
        "        generated = [\"[START]\"] * (self.order)\n",
        "        word = None\n",
        "        while word != \"[END]\":\n",
        "            context = ' '.join(generated[-self.order:] if self.order > 0 else \"\")\n",
        "            word = self.sample(context)\n",
        "            generated.append(word)\n",
        "        if not keep_ends:\n",
        "            generated = generated[self.order:-1]\n",
        "        return \" \".join(generated)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "81a51b9e",
      "metadata": {
        "id": "81a51b9e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "defc7656-586f-47cc-cc94-b3052081c1d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[START]', 'Chapter', '1', 'It', 'is', 'a', 'truth', 'universally', 'acknowledged', ',', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', ',', 'must', 'be', 'in', 'want', 'of', 'a', 'wife', '.', '[END]']\n",
            "Context: [START]                                            Next: Chapter\n",
            "Context: Chapter                                            Next: 1\n",
            "Context: 1                                                  Next: It\n",
            "Context: It                                                 Next: is\n",
            "Context: is                                                 Next: a\n",
            "Context: a                                                  Next: truth\n",
            "Context: truth                                              Next: universally\n",
            "Context: universally                                        Next: acknowledged\n",
            "Context: acknowledged                                       Next: ,\n",
            "Context: ,                                                  Next: that\n",
            "Context: that                                               Next: a\n",
            "Context: a                                                  Next: single\n",
            "Context: single                                             Next: man\n",
            "Context: man                                                Next: in\n",
            "Context: in                                                 Next: possession\n",
            "Context: possession                                         Next: of\n",
            "Context: of                                                 Next: a\n",
            "Context: a                                                  Next: good\n",
            "Context: good                                               Next: fortune\n",
            "Context: fortune                                            Next: ,\n",
            "Context: ,                                                  Next: must\n",
            "Context: must                                               Next: be\n",
            "Context: be                                                 Next: in\n",
            "Context: in                                                 Next: want\n",
            "Context: want                                               Next: of\n",
            "Context: of                                                 Next: a\n",
            "Context: a                                                  Next: wife\n",
            "Context: wife                                               Next: .\n",
            "Context: .                                                  Next: [END]\n"
          ]
        }
      ],
      "source": [
        "ngram1 = NgramModel(sequences[:max_sequences], order=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "c79935c2",
      "metadata": {
        "id": "c79935c2",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d74c66f2-d2c6-4e07-cdbe-4c45e8f1b2b0"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[START] why she practised more to admire , and form the young man . [END]\n"
          ]
        }
      ],
      "source": [
        "print(ngram1.generate_sequence())"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "ad8a2c8d",
      "metadata": {
        "id": "ad8a2c8d",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d215bc36-7904-48f5-b7a9-c4425aa35886"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['Chapter', '1', 'It', 'is', 'a', 'truth', 'universally', 'acknowledged', ',', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', ',', 'must', 'be', 'in', 'want', 'of', 'a', 'wife', '.', '[END]']\n",
            "Context:                                                    Next: Chapter\n",
            "Context:                                                    Next: 1\n",
            "Context:                                                    Next: It\n",
            "Context:                                                    Next: is\n",
            "Context:                                                    Next: a\n",
            "Context:                                                    Next: truth\n",
            "Context:                                                    Next: universally\n",
            "Context:                                                    Next: acknowledged\n",
            "Context:                                                    Next: ,\n",
            "Context:                                                    Next: that\n",
            "Context:                                                    Next: a\n",
            "Context:                                                    Next: single\n",
            "Context:                                                    Next: man\n",
            "Context:                                                    Next: in\n",
            "Context:                                                    Next: possession\n",
            "Context:                                                    Next: of\n",
            "Context:                                                    Next: a\n",
            "Context:                                                    Next: good\n",
            "Context:                                                    Next: fortune\n",
            "Context:                                                    Next: ,\n",
            "Context:                                                    Next: must\n",
            "Context:                                                    Next: be\n",
            "Context:                                                    Next: in\n",
            "Context:                                                    Next: want\n",
            "Context:                                                    Next: of\n",
            "Context:                                                    Next: a\n",
            "Context:                                                    Next: wife\n",
            "Context:                                                    Next: .\n",
            "Context:                                                    Next: [END]\n"
          ]
        }
      ],
      "source": [
        "ngram0 = NgramModel(sequences[:max_sequences], order=0)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "6982433e",
      "metadata": {
        "id": "6982433e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e635bbd1-3971-4d59-e3e3-1bae12acc489"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'read incumbent and Mrs. had He [END]'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ],
      "source": [
        "ngram0.generate_sequence()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "35ee1ead",
      "metadata": {
        "id": "35ee1ead",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d0a355a5-b27d-4ee4-c1f4-839215317a83"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[START]', '[START]', 'Chapter', '1', 'It', 'is', 'a', 'truth', 'universally', 'acknowledged', ',', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', ',', 'must', 'be', 'in', 'want', 'of', 'a', 'wife', '.', '[END]']\n",
            "Context: [START] [START]                                    Next: Chapter\n",
            "Context: [START] Chapter                                    Next: 1\n",
            "Context: Chapter 1                                          Next: It\n",
            "Context: 1 It                                               Next: is\n",
            "Context: It is                                              Next: a\n",
            "Context: is a                                               Next: truth\n",
            "Context: a truth                                            Next: universally\n",
            "Context: truth universally                                  Next: acknowledged\n",
            "Context: universally acknowledged                           Next: ,\n",
            "Context: acknowledged ,                                     Next: that\n",
            "Context: , that                                             Next: a\n",
            "Context: that a                                             Next: single\n",
            "Context: a single                                           Next: man\n",
            "Context: single man                                         Next: in\n",
            "Context: man in                                             Next: possession\n",
            "Context: in possession                                      Next: of\n",
            "Context: possession of                                      Next: a\n",
            "Context: of a                                               Next: good\n",
            "Context: a good                                             Next: fortune\n",
            "Context: good fortune                                       Next: ,\n",
            "Context: fortune ,                                          Next: must\n",
            "Context: , must                                             Next: be\n",
            "Context: must be                                            Next: in\n",
            "Context: be in                                              Next: want\n",
            "Context: in want                                            Next: of\n",
            "Context: want of                                            Next: a\n",
            "Context: of a                                               Next: wife\n",
            "Context: a wife                                             Next: .\n",
            "Context: wife .                                             Next: [END]\n"
          ]
        }
      ],
      "source": [
        "ngram2 = NgramModel(sequences[:max_sequences], order=2)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "24378b79",
      "metadata": {
        "id": "24378b79",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "c02b8c3c-460a-4428-9aac-1d21d7b3a2c8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'We _will_ know where I can assure you in such a proof of its animation , and she read it , as if engaged in the North , just when she rose as she chooses. ” “ Their conduct has been the work of a common and transient liking , which Elizabeth wondered Lady Catherine .'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 11
        }
      ],
      "source": [
        "ngram2.generate_sequence(keep_ends=False)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49e0fe5d",
      "metadata": {
        "id": "49e0fe5d"
      },
      "source": [
        "**Q1**. Explore sampling sequences from LMs of different orders above; what do you notice about the structure of the generated texts (and how they differ by orders)?  Explore LMs trained on different datasets as well."
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "The Markov order is essentially the side of a window of context that allows the LM to determine the next word. ngram0 seems to make the least sense, and ngram2 the most sense intuitively. ngram0 is also short, and ngram2 is longest."
      ],
      "metadata": {
        "id": "i5cmJftrVCrt"
      },
      "id": "i5cmJftrVCrt"
    },
    {
      "cell_type": "markdown",
      "id": "61c57df0",
      "metadata": {
        "id": "61c57df0"
      },
      "source": [
        "**Q2.** In a second-order LM estimated from `1342_pride_and_prejudice.txt` above, what's $P(\\textrm{are} | \\textrm{Lady Lucas})$?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Should be 0, because 'are' should not appear after 'Lady Lucas'. The second order LM has context of 'Lady Lucas', and can therefore determine that 'are' is not a good next word candidate."
      ],
      "metadata": {
        "id": "WU-0wpZKWxkE"
      },
      "id": "WU-0wpZKWxkE"
    },
    {
      "cell_type": "markdown",
      "id": "da32d0e0",
      "metadata": {
        "id": "da32d0e0"
      },
      "source": [
        "**Q3.** Keep increasing the order of LMs (well past 3); compare the text that's generated to the original dataset (in the files above); are the LMs simply memorizing the source material?"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "ngram5 = NgramModel(sequences[:max_sequences], order=5)\n",
        "ngram5.generate_sequence()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 621
        },
        "id": "n-De6Qx9XeIG",
        "outputId": "30f23f9f-bc13-44e0-d483-d3bcf7dc4ac7"
      },
      "id": "n-De6Qx9XeIG",
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['[START]', '[START]', '[START]', '[START]', '[START]', 'Chapter', '1', 'It', 'is', 'a', 'truth', 'universally', 'acknowledged', ',', 'that', 'a', 'single', 'man', 'in', 'possession', 'of', 'a', 'good', 'fortune', ',', 'must', 'be', 'in', 'want', 'of', 'a', 'wife', '.', '[END]']\n",
            "Context: [START] [START] [START] [START] [START]            Next: Chapter\n",
            "Context: [START] [START] [START] [START] Chapter            Next: 1\n",
            "Context: [START] [START] [START] Chapter 1                  Next: It\n",
            "Context: [START] [START] Chapter 1 It                       Next: is\n",
            "Context: [START] Chapter 1 It is                            Next: a\n",
            "Context: Chapter 1 It is a                                  Next: truth\n",
            "Context: 1 It is a truth                                    Next: universally\n",
            "Context: It is a truth universally                          Next: acknowledged\n",
            "Context: is a truth universally acknowledged                Next: ,\n",
            "Context: a truth universally acknowledged ,                 Next: that\n",
            "Context: truth universally acknowledged , that              Next: a\n",
            "Context: universally acknowledged , that a                  Next: single\n",
            "Context: acknowledged , that a single                       Next: man\n",
            "Context: , that a single man                                Next: in\n",
            "Context: that a single man in                               Next: possession\n",
            "Context: a single man in possession                         Next: of\n",
            "Context: single man in possession of                        Next: a\n",
            "Context: man in possession of a                             Next: good\n",
            "Context: in possession of a good                            Next: fortune\n",
            "Context: possession of a good fortune                       Next: ,\n",
            "Context: of a good fortune ,                                Next: must\n",
            "Context: a good fortune , must                              Next: be\n",
            "Context: good fortune , must be                             Next: in\n",
            "Context: fortune , must be in                               Next: want\n",
            "Context: , must be in want                                  Next: of\n",
            "Context: must be in want of                                 Next: a\n",
            "Context: be in want of a                                    Next: wife\n",
            "Context: in want of a wife                                  Next: .\n",
            "Context: want of a wife .                                   Next: [END]\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[START] [START] [START] [START] [START] I assure you it is much larger than Sir William Lucas's. ” “ This must be a most inconvenient sitting room for the evening , in summer ; the windows are full west. ” Mrs. Bennet assured her that they never sat there after dinner , and then added : “ May I take the liberty of asking your ladyship whether you left Mr. and Mrs. Collins well. ” “ Yes , very indifferent indeed , ” said Elizabeth , “ and how much is settled on his side on our sister , we shall exactly know what Mr. Gardiner has done for them , because Wickham has not sixpence of his own . [END]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}