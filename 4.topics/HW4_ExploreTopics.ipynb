{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/info256-applied-nlp/blob/main/4.topics/HW4_ExploreTopics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5FdE_BKEVVq"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp25/blob/main/4.topics/HW4_ExploreTopics.ipynb)\n",
        "\n",
        "**N.B.** Once it's open on Colab, remember to save a copy (by e.g. clicking `Copy to Drive` above).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzmdE4_yHpHG"
      },
      "source": [
        "# HW4: Exploring topics\n",
        "In this homework, you have an open-ended task: tell us something **interesting** about a collection of text data using topic modeling. You can choose between the following datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PU0NSxn-bZR"
      },
      "source": [
        "In `acl.all.tsv` you'll find 7,188 papers published at major NLP venues (ACL, EMNLP, NAACL, TACL, etc.) between 2013 and 2020.  Here is a sample of that data:\n",
        "\n",
        "|id|year of publication|title|abstract|\n",
        "|---|---|---|---|\n",
        "|pimentel-etal-2020-phonotactic|2020|Phonotactic Complexity and Its Trade-offs|We present methods for calculating a measure of phonotactic complexity ...|\n",
        "|wang-etal-2020-amr|2020|AMR-To-Text Generation with Graph Transformer|Abstract meaning representation (AMR)-to-text generation is the challenging task  ...|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I75gEBBz-4AR"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/acl.all.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abup6G02FAXU"
      },
      "source": [
        "In `gutenberg.genre.tsv` you'll find 1,250 passages of English-language fiction from Project Gutenberg, categorized by genre (adventure, detective, love stories, science fiction, westerns).  Here's a sample:\n",
        "\n",
        "|id|genre|author|passage|\n",
        "|---|---|---|---|\n",
        "|66390_1796\t|love stories\t|Prime-Stevenson, Edward\t|Only a few days absence. I shall think of you. Imre. P. S. Please write me.\" I was amused,  ...|\n",
        "|50157_2780\t|detective and mystery stories|\tWheeler, Janet D.\t|Edina shook her head. “They think I’ve lied to them. They think I’ve cheated them. They want their money, and you can’t rightly blame them...|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "S8oqE9GqFR5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d29938e5-9f78-4ac9-ada2-473e3fd49a64"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 18:14:19--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/gutenberg.genre.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2766963 (2.6M) [text/plain]\n",
            "Saving to: ‘gutenberg.genre.tsv.1’\n",
            "\n",
            "gutenberg.genre.tsv 100%[===================>]   2.64M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-09-20 18:14:19 (35.9 MB/s) - ‘gutenberg.genre.tsv.1’ saved [2766963/2766963]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/gutenberg.genre.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVjaykL2I_50"
      },
      "source": [
        "In `convote.train.tsv`, you'll find 2,723 dialogue turns from the Convote dataset on congressional speeches, paired with the party affiliation of the speaker (Democrat/Republican). Here's a sample:\n",
        "\n",
        "|party|passage|\n",
        "|---|---|\n",
        "|R\t|mr. speaker , i claim the time in opposition to the motion to recommit .|\n",
        "|D\t|mr. speaker , on that i demand the yeas and nays .|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86UzkCXtLBF8"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/convote.train.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NqJX9w1H1cp"
      },
      "source": [
        "Choose one of these datasets and use topic modeling as exploratory data analysis to find some interesting structure in that data.  There are only two constraints:\n",
        "\n",
        "* You must use topic modeling to find topics in the data\n",
        "* You must relate those **topics** to some aspect of the metadata. Examples of this could be: charting the rise and fall of **topics** over time (i.e., with year of publication as metadata) or associating **topics** with genre to find which topics are more aligned one one genre over another (perhaps using some of the measures of association we talked about earlier this semester)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHp0qGRvIc24"
      },
      "source": [
        "## Part 1: topic modeling\n",
        "\n",
        "Q1: Try creating several topic models with different parameters for the _number_ of topics. Compare the outputs, and decide what number of topics is most reasonable for your dataset. **In a couple of sentences, justify your selection.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZLTiQiC283Z",
        "outputId": "0feaa9e4-6d5c-4a7e-dab1-23bd5c77d768"
      },
      "execution_count": 89,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from gensim import corpora\n",
        "from tqdm import tqdm  # for progress bars\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "random.seed(1)"
      ],
      "metadata": {
        "id": "q36yk50s_e3e",
        "outputId": "979bde5f-2b7d-4856-ba96-1c4dd7c54d78",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 90,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/main/data/jockers.stopwords"
      ],
      "metadata": {
        "id": "SfiEwVYd_u4g",
        "outputId": "d1ba4b70-25aa-4aae-eee1-c34af06a3ad5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 91,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 18:14:48--  https://raw.githubusercontent.com/dbamman/anlp25/main/data/jockers.stopwords\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44453 (43K) [text/plain]\n",
            "Saving to: ‘jockers.stopwords.2’\n",
            "\n",
            "\rjockers.stopwords.2   0%[                    ]       0  --.-KB/s               \rjockers.stopwords.2 100%[===================>]  43.41K  --.-KB/s    in 0.01s   \n",
            "\n",
            "2025-09-20 18:14:48 (3.86 MB/s) - ‘jockers.stopwords.2’ saved [44453/44453]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_stopwords(filename):\n",
        "    \"\"\"Reads a file of stopwords into a set.\"\"\"\n",
        "    stopwords = set([\n",
        "        line.rstrip() for line in open(filename)\n",
        "    ])\n",
        "    return stopwords"
      ],
      "metadata": {
        "id": "uAbuE26vBvbS"
      },
      "execution_count": 115,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words = stop_words | read_stopwords(\"jockers.stopwords\")\n",
        "stop_words.add(\"'s\")\n",
        "stop_words=list(stop_words)"
      ],
      "metadata": {
        "id": "yngVkMp5ODws"
      },
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r\"[A-Za-z]\")\n",
        "def stopword_filter(word, stopwords):\n",
        "    \"\"\" Function to exclude words from a text.\"\"\"\n",
        "\n",
        "    # no stopwords\n",
        "    if word in stopwords:\n",
        "        return False\n",
        "\n",
        "    # has to contain at least one letter\n",
        "    if pattern.search(word) is not None:\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "veijOX2dB3SD"
      },
      "execution_count": 118,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Kr8s1C236o"
      },
      "source": [
        "Q2: Using the topic model with the number of topics that you selected, identify a couple of topics that are coherent. **In a paragraph, interpret these topics (i.e., by giving them a name / description). Support your answer with evidence from word and/or document distributions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY6a8hcw236o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gvm3nxa236o"
      },
      "source": [
        "## Part 2: analysis\n",
        "\n",
        "Q3: Relate the topics to some aspect of the metadata. These don't have to be the same topics that you described in question 2. **Write a paragraph synthesizing your findings, and provide quantitative evidence.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcRlSo4j236o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHkbbMbLbKR5"
      },
      "source": [
        "---\n",
        "\n",
        "## To submit\n",
        "\n",
        "Congratulations on finishing this homework!\n",
        "Please follow the instructions below to download the notebook file (`.ipynb`) and its printed version (`.pdf`) for submission on bCourses -- remember **all cells must be executed**.\n",
        "\n",
        "1.  Download a copy of the notebook file: `File > Download > Download .ipynb`.\n",
        "\n",
        "2.  Print the notebook as PDF (via your browser, or tools like [nbconvert](https://nbconvert.readthedocs.io/en/latest/))."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}