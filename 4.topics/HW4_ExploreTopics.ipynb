{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/info256-applied-nlp/blob/main/4.topics/HW4_ExploreTopics.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5FdE_BKEVVq"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp25/blob/main/4.topics/HW4_ExploreTopics.ipynb)\n",
        "\n",
        "**N.B.** Once it's open on Colab, remember to save a copy (by e.g. clicking `Copy to Drive` above).\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JzmdE4_yHpHG"
      },
      "source": [
        "# HW4: Exploring topics\n",
        "In this homework, you have an open-ended task: tell us something **interesting** about a collection of text data using topic modeling. You can choose between the following datasets:"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PU0NSxn-bZR"
      },
      "source": [
        "In `acl.all.tsv` you'll find 7,188 papers published at major NLP venues (ACL, EMNLP, NAACL, TACL, etc.) between 2013 and 2020.  Here is a sample of that data:\n",
        "\n",
        "|id|year of publication|title|abstract|\n",
        "|---|---|---|---|\n",
        "|pimentel-etal-2020-phonotactic|2020|Phonotactic Complexity and Its Trade-offs|We present methods for calculating a measure of phonotactic complexity ...|\n",
        "|wang-etal-2020-amr|2020|AMR-To-Text Generation with Graph Transformer|Abstract meaning representation (AMR)-to-text generation is the challenging task  ...|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "I75gEBBz-4AR"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/acl.all.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Abup6G02FAXU"
      },
      "source": [
        "In `gutenberg.genre.tsv` you'll find 1,250 passages of English-language fiction from Project Gutenberg, categorized by genre (adventure, detective, love stories, science fiction, westerns).  Here's a sample:\n",
        "\n",
        "|id|genre|author|passage|\n",
        "|---|---|---|---|\n",
        "|66390_1796\t|love stories\t|Prime-Stevenson, Edward\t|Only a few days absence. I shall think of you. Imre. P. S. Please write me.\" I was amused,  ...|\n",
        "|50157_2780\t|detective and mystery stories|\tWheeler, Janet D.\t|Edina shook her head. “They think I’ve lied to them. They think I’ve cheated them. They want their money, and you can’t rightly blame them...|\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "S8oqE9GqFR5N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "9fe3cca7-77f3-44ae-d3af-cd7753a92dce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 16:37:48--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/gutenberg.genre.tsv\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 2766963 (2.6M) [text/plain]\n",
            "Saving to: ‘gutenberg.genre.tsv’\n",
            "\n",
            "\rgutenberg.genre.tsv   0%[                    ]       0  --.-KB/s               \rgutenberg.genre.tsv 100%[===================>]   2.64M  --.-KB/s    in 0.07s   \n",
            "\n",
            "2025-09-20 16:37:48 (36.7 MB/s) - ‘gutenberg.genre.tsv’ saved [2766963/2766963]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/gutenberg.genre.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MVjaykL2I_50"
      },
      "source": [
        "In `convote.train.tsv`, you'll find 2,723 dialogue turns from the Convote dataset on congressional speeches, paired with the party affiliation of the speaker (Democrat/Republican). Here's a sample:\n",
        "\n",
        "|party|passage|\n",
        "|---|---|\n",
        "|R\t|mr. speaker , i claim the time in opposition to the motion to recommit .|\n",
        "|D\t|mr. speaker , on that i demand the yeas and nays .|"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "86UzkCXtLBF8"
      },
      "outputs": [],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/convote.train.tsv"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7NqJX9w1H1cp"
      },
      "source": [
        "Choose one of these datasets and use topic modeling as exploratory data analysis to find some interesting structure in that data.  There are only two constraints:\n",
        "\n",
        "* You must use topic modeling to find topics in the data\n",
        "* You must relate those **topics** to some aspect of the metadata. Examples of this could be: charting the rise and fall of **topics** over time (i.e., with year of publication as metadata) or associating **topics** with genre to find which topics are more aligned one one genre over another (perhaps using some of the measures of association we talked about earlier this semester)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OHp0qGRvIc24"
      },
      "source": [
        "## Part 1: topic modeling\n",
        "\n",
        "Q1: Try creating several topic models with different parameters for the _number_ of topics. Compare the outputs, and decide what number of topics is most reasonable for your dataset. **In a couple of sentences, justify your selection.**"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install gensim"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DZLTiQiC283Z",
        "outputId": "9fc4926b-5e7b-46c2-a304-12ec507fad8a"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.12/dist-packages (4.3.3)\n",
            "Requirement already satisfied: numpy<2.0,>=1.18.5 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.26.4)\n",
            "Requirement already satisfied: scipy<1.14.0,>=1.7.0 in /usr/local/lib/python3.12/dist-packages (from gensim) (1.13.1)\n",
            "Requirement already satisfied: smart-open>=1.8.1 in /usr/local/lib/python3.12/dist-packages (from gensim) (7.3.1)\n",
            "Requirement already satisfied: wrapt in /usr/local/lib/python3.12/dist-packages (from smart-open>=1.8.1->gensim) (1.17.3)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import operator\n",
        "import re\n",
        "\n",
        "import nltk\n",
        "from gensim import corpora\n",
        "from tqdm import tqdm  # for progress bars\n",
        "\n",
        "nltk.download(\"stopwords\")\n",
        "nltk.download(\"punkt\")\n",
        "nltk.download(\"punkt_tab\")\n",
        "import random\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "random.seed(1)"
      ],
      "metadata": {
        "id": "q36yk50s_e3e",
        "outputId": "2fe1af7e-da56-4592-a304-aed1b6e7c737",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n",
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Package punkt is already up-to-date!\n",
            "[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n",
            "[nltk_data]   Package punkt_tab is already up-to-date!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/main/data/jockers.stopwords"
      ],
      "metadata": {
        "id": "SfiEwVYd_u4g",
        "outputId": "1b24f3d2-6434-4ffe-f56d-95a7a2f6bc56",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-09-20 17:42:45--  https://raw.githubusercontent.com/dbamman/anlp25/main/data/jockers.stopwords\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.111.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.111.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 44453 (43K) [text/plain]\n",
            "Saving to: ‘jockers.stopwords.1’\n",
            "\n",
            "\rjockers.stopwords.1   0%[                    ]       0  --.-KB/s               \rjockers.stopwords.1 100%[===================>]  43.41K  --.-KB/s    in 0.02s   \n",
            "\n",
            "2025-09-20 17:42:46 (2.72 MB/s) - ‘jockers.stopwords.1’ saved [44453/44453]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def read_stopwords(filename):\n",
        "    \"\"\"Reads a file of stopwords into a set.\"\"\"\n",
        "    stopwords = set([\n",
        "        line.rstrip() for line in open(filename)\n",
        "    ])\n",
        "    return stopwords"
      ],
      "metadata": {
        "id": "uAbuE26vBvbS"
      },
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stop_words = set(stopwords.words('english'))\n",
        "stop_words = stop_words | read_stopwords(\"jockers.stopwords\")\n",
        "stop_words.add(\"'s\")\n",
        "stop_words.add(\"n't\") # add another nonesense token that keeps appearing for some reason\n",
        "stop_words=list(stop_words)"
      ],
      "metadata": {
        "id": "yngVkMp5ODws"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pattern = re.compile(r\"[A-Za-z]\")\n",
        "def stopword_filter(word, stopwords):\n",
        "    \"\"\" Function to exclude words from a text.\"\"\"\n",
        "\n",
        "    # no stopwords\n",
        "    if word in stopwords:\n",
        "        return False\n",
        "\n",
        "    # has to contain at least one letter\n",
        "    if pattern.search(word) is not None:\n",
        "        return True\n",
        "\n",
        "    return False"
      ],
      "metadata": {
        "id": "veijOX2dB3SD"
      },
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import string\n",
        "\n",
        "def clean_token(token):\n",
        "    return token.strip(string.punctuation)"
      ],
      "metadata": {
        "id": "IYJqDj5vSFph"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def read_gutenberg(filename, stopwords):\n",
        "    '''\n",
        "    Adapted function from TopicModel.ipynb for gutenberg corpus\n",
        "    Four columns: id, genre, author, text\n",
        "    '''\n",
        "    df = pd.read_csv(filename, sep=\"\\t\", names=[\"id\", \"genre\", \"author\", \"text\"])\n",
        "\n",
        "    def tokenize_and_process(text):\n",
        "      return [\n",
        "          clean_token(x)\n",
        "          for x in nltk.word_tokenize(str(text).lower())\n",
        "          if stopword_filter(clean_token(x), stop_words)\n",
        "      ]\n",
        "\n",
        "    docs = []\n",
        "    for txt in tqdm(df.txt.fillna(\"\")):\n",
        "        docs.append(tokenize_and_process(text))\n",
        "\n",
        "    names = df.genre.to_list()   # fetch genre col\n",
        "    return docs, names"
      ],
      "metadata": {
        "id": "9U9TY313GrTC"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs, names = read_gutenberg(\"gutenberg.genre.tsv\", stop_words)"
      ],
      "metadata": {
        "id": "hUhOpPU6PTwq",
        "outputId": "ed5d0a1f-f51b-4714-bfe4-c7b9b8632f5f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 1247/1247 [00:43<00:00, 28.83it/s]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dictionary = corpora.Dictionary(docs)\n",
        "dictionary.filter_extremes(no_below=5, no_above=0.2, keep_n=10000) # modified no_above to 0.3\n",
        "corpus = [dictionary.doc2bow(text) for text in docs]"
      ],
      "metadata": {
        "id": "1J9dR7zqPoSB"
      },
      "execution_count": 79,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import gensim\n",
        "\n",
        "lda_model20 = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=20,\n",
        "    passes=10,\n",
        "    alpha='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "PKv7_8qn3BbF"
      },
      "execution_count": 81,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(20):\n",
        "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model20.show_topic(i, topn=10)])))"
      ],
      "metadata": {
        "id": "5B8LbIwtPxje",
        "outputId": "34d97686-f370-433a-da95-519db1ff52a5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 82,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0:\tdoor sir girls lord girl seen letter heard hour gone\n",
            "topic 1:\tdr father dark work st house light suddenly heard lawyer\n",
            "topic 2:\tfather quite door ter help girl done ye git fer\n",
            "topic 3:\tcaptain people big give gentleman girl morning course sure sir\n",
            "topic 4:\tmean course trouble woman things believe give girl wife child\n",
            "topic 5:\thorse woman house word people door mind race side brought\n",
            "topic 6:\tfire cash close feathers cabin mayor sound means tried door\n",
            "topic 7:\tpole give people sir light read division quite days big\n",
            "topic 8:\twoman door work kiron help nature mackinney heart days created\n",
            "topic 9:\tsir door leave seen heard gone father days captain stood\n",
            "topic 10:\tlight door want sir captain vogel heard window small began\n",
            "topic 11:\tth horse country house sir rode yo aw big people\n",
            "topic 12:\twork sure people course want set big river side guess\n",
            "topic 13:\tbork prosecutor want water prokle feet light hour things side\n",
            "topic 14:\tweapon white yuh point yore heart sure figure space seen\n",
            "topic 15:\tde girls coroner dworken show quite matter martian suddenly mind\n",
            "topic 16:\tdoor white want sure sat mother things girl felt sir\n",
            "topic 17:\tfelt grafton marsden grand duke uncle happened house girl boy\n",
            "topic 18:\tkennedy want morning money boy doctor story ye heard black\n",
            "topic 19:\tperk earth things years lay house kind course mean name\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model10 = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=10,\n",
        "    passes=10,\n",
        "    alpha='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "jct17MEWQCrc"
      },
      "execution_count": 83,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(10):\n",
        "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model10.show_topic(i, topn=10)])))"
      ],
      "metadata": {
        "id": "m0EmPb2mQEML",
        "outputId": "830244c6-090a-4006-e6d2-c4d4d6a257b3",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0:\tcaptain coroner years sir people boy days dark felt happened\n",
            "topic 1:\tde door boy stood table house gave quite work word\n",
            "topic 2:\twoman felt door things girl people gone work white heart\n",
            "topic 3:\tth want house water horse perk sure uncle river things\n",
            "topic 4:\tfather mother girl want stood woman child door felt morning\n",
            "topic 5:\tpeople girl world course quite want give name really sure\n",
            "topic 6:\tbork de prosecutor case matter need things big moved natural\n",
            "topic 7:\tmarsden yuh people prale set carlin things days work big\n",
            "topic 8:\tdoor light heard open side ship water air feet white\n",
            "topic 9:\tsir th kennedy north heard want dead course range inspector\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lda_model5 = gensim.models.ldamodel.LdaModel(\n",
        "    corpus=corpus,\n",
        "    id2word=dictionary,\n",
        "    num_topics=5,\n",
        "    passes=10,\n",
        "    alpha='auto'\n",
        ")"
      ],
      "metadata": {
        "id": "DBXtVvNDQPTi"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(5):\n",
        "    print(\"topic %s:\\t%s\" % (i, ' '.join([term for term, freq in lda_model5.show_topic(i, topn=10)])))"
      ],
      "metadata": {
        "id": "ydN7YeN6QTLf",
        "outputId": "0ed0078b-04ed-432d-96a6-b7597debd955",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "topic 0:\tth big sure feet side water perk horse felt dead\n",
            "topic 1:\tpeople white light work things gone captain ship seen morning\n",
            "topic 2:\tdoor sir quite course people stood black want heard things\n",
            "topic 3:\tdoor heard sir began small horse kennedy returned coroner stood\n",
            "topic 4:\tgirl house woman want sir door give de course felt\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "97Kr8s1C236o"
      },
      "source": [
        "Q2: Using the topic model with the number of topics that you selected, identify a couple of topics that are coherent. **In a paragraph, interpret these topics (i.e., by giving them a name / description). Support your answer with evidence from word and/or document distributions.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lY6a8hcw236o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1Gvm3nxa236o"
      },
      "source": [
        "## Part 2: analysis\n",
        "\n",
        "Q3: Relate the topics to some aspect of the metadata. These don't have to be the same topics that you described in question 2. **Write a paragraph synthesizing your findings, and provide quantitative evidence.**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gcRlSo4j236o"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SHkbbMbLbKR5"
      },
      "source": [
        "---\n",
        "\n",
        "## To submit\n",
        "\n",
        "Congratulations on finishing this homework!\n",
        "Please follow the instructions below to download the notebook file (`.ipynb`) and its printed version (`.pdf`) for submission on bCourses -- remember **all cells must be executed**.\n",
        "\n",
        "1.  Download a copy of the notebook file: `File > Download > Download .ipynb`.\n",
        "\n",
        "2.  Print the notebook as PDF (via your browser, or tools like [nbconvert](https://nbconvert.readthedocs.io/en/latest/))."
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}