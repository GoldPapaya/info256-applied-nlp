{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/info256-applied-nlp/blob/main/11.nlp/HW10_SyntacticRelations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZiz11AmYpcP"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp25/blob/main/11.nlp/HW10_SyntacticRelations.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYkjH_3dljL"
      },
      "source": [
        "# HW10: Exploring gender in books\n",
        "\n",
        "This notebook explores dependency parsing by identifying the actions and objects that are characteristically associated with characters as a function of their referential gender (\"he\"/\"she\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m4OX0TrLdljO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import operator\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Iv37AaPdljQ"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLC5EUZ9YpcR"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5CKftUPdljQ"
      },
      "source": [
        "We'll run seven novels by Jane Austen through spaCy (this will take a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uBFrBn1wd2wj",
        "outputId": "588022eb-e8e7-4281-971a-58d0815f28c7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-08 19:31:00--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/emma.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 927445 (906K) [text/plain]\n",
            "Saving to: ‘emma.txt’\n",
            "\n",
            "emma.txt            100%[===================>] 905.71K  5.34MB/s    in 0.2s    \n",
            "\n",
            "2025-11-08 19:31:00 (5.34 MB/s) - ‘emma.txt’ saved [927445/927445]\n",
            "\n",
            "--2025-11-08 19:31:00--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/lady_susan.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149538 (146K) [text/plain]\n",
            "Saving to: ‘lady_susan.txt’\n",
            "\n",
            "lady_susan.txt      100%[===================>] 146.03K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-11-08 19:31:01 (1.80 MB/s) - ‘lady_susan.txt’ saved [149538/149538]\n",
            "\n",
            "--2025-11-08 19:31:01--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/mansfield_park.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 925067 (903K) [text/plain]\n",
            "Saving to: ‘mansfield_park.txt’\n",
            "\n",
            "mansfield_park.txt  100%[===================>] 903.39K  5.33MB/s    in 0.2s    \n",
            "\n",
            "2025-11-08 19:31:01 (5.33 MB/s) - ‘mansfield_park.txt’ saved [925067/925067]\n",
            "\n",
            "--2025-11-08 19:31:01--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/northanger_abbey.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.108.133, 185.199.109.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 465393 (454K) [text/plain]\n",
            "Saving to: ‘northanger_abbey.txt’\n",
            "\n",
            "northanger_abbey.tx 100%[===================>] 454.49K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-08 19:31:02 (3.44 MB/s) - ‘northanger_abbey.txt’ saved [465393/465393]\n",
            "\n",
            "--2025-11-08 19:31:02--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/persuasion.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494990 (483K) [text/plain]\n",
            "Saving to: ‘persuasion.txt’\n",
            "\n",
            "persuasion.txt      100%[===================>] 483.39K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-08 19:31:03 (3.61 MB/s) - ‘persuasion.txt’ saved [494990/494990]\n",
            "\n",
            "--2025-11-08 19:31:03--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/pride.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.110.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 704832 (688K) [text/plain]\n",
            "Saving to: ‘pride.txt’\n",
            "\n",
            "pride.txt           100%[===================>] 688.31K  4.33MB/s    in 0.2s    \n",
            "\n",
            "2025-11-08 19:31:03 (4.33 MB/s) - ‘pride.txt’ saved [704832/704832]\n",
            "\n",
            "--2025-11-08 19:31:03--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/sense_and_sensibility.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 706124 (690K) [text/plain]\n",
            "Saving to: ‘sense_and_sensibility.txt’\n",
            "\n",
            "sense_and_sensibili 100%[===================>] 689.57K  4.33MB/s    in 0.2s    \n",
            "\n",
            "2025-11-08 19:31:04 (4.33 MB/s) - ‘sense_and_sensibility.txt’ saved [706124/706124]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/emma.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/lady_susan.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/mansfield_park.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/northanger_abbey.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/persuasion.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/pride.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/sense_and_sensibility.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nyq6Xhx6dljQ",
        "outputId": "96f92f2b-c537-482e-d32a-c22d67568a77",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [03:03<00:00, 26.27s/it]\n"
          ]
        }
      ],
      "source": [
        "files = [\"emma.txt\", \"lady_susan.txt\", \"mansfield_park.txt\", \"northanger_abbey.txt\", \"persuasion.txt\", \"pride.txt\", \"sense_and_sensibility.txt\"]\n",
        "\n",
        "def read_all_files(filenames):\n",
        "    all_tokens = []\n",
        "\n",
        "    for filename in tqdm(filenames):\n",
        "        data = open(filename, encoding=\"utf-8\").read()\n",
        "        tokens = nlp(data)\n",
        "        all_tokens.extend(tokens)\n",
        "    return all_tokens\n",
        "\n",
        "all_tokens = read_all_files(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MOIwxtVydljR",
        "outputId": "53dcc03c-9b53-4374-8db8-937cfc3c3390",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "972810\n"
          ]
        }
      ],
      "source": [
        "print(len(all_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJHqhcmoYpcT"
      },
      "source": [
        "## Setting up log odds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FmCkFJy6dljR"
      },
      "outputs": [],
      "source": [
        "def logodds(counter1, counter2, display=25):\n",
        "    \"\"\"\n",
        "    Function that takes two Counter objects as inputs and prints out a ranked list of terms\n",
        "    more characteristic of the first counter than the second.  Here we'll use log-odds\n",
        "    with an uninformative prior (from Monroe et al 2008, \"Fightin Words\", eqn. 22) as our metric.\n",
        "\n",
        "    \"Category 1\" corresponds to the category of the counter1 object (the first argument)\n",
        "    \"Category 2\" corresponds to the category of the counter2 object (the second argument)\n",
        "    \"\"\"\n",
        "    vocab=dict(counter1)\n",
        "    vocab.update(dict(counter2))\n",
        "    count1_sum=sum(counter1.values())\n",
        "    count2_sum=sum(counter2.values())\n",
        "\n",
        "    ranks={}\n",
        "    alpha=0.01\n",
        "    alphaV=len(vocab)*alpha\n",
        "\n",
        "    for word in vocab:\n",
        "\n",
        "        log_odds_ratio=math.log( (counter1[word] + alpha) / (count1_sum+alphaV-counter1[word]-alpha) ) - math.log( (counter2[word] + alpha) / (count2_sum+alphaV-counter2[word]-alpha) )\n",
        "        variance=1./(counter1[word] + alpha) + 1./(counter2[word] + alpha)\n",
        "\n",
        "        ranks[word]=log_odds_ratio/math.sqrt(variance)\n",
        "\n",
        "    sorted_x = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "    print(\"Most category 1:\")\n",
        "    for k,v in sorted_x[:display]:\n",
        "        print(\"%.3f\\t%s\" % (v,k))\n",
        "\n",
        "    print(\"\\nMost category 2:\")\n",
        "    for k,v in reversed(sorted_x[-display:]):\n",
        "        print(\"%.3f\\t%s\" % (v,k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhvQ2pEMYpcU"
      },
      "source": [
        "## Dependency parsing with SpaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njbslDssdljS"
      },
      "source": [
        "SpaCy uses the [ClearNLP dependency labels](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md), which are very close to the Stanford typed dependencies.  See the [Stanford dependencies manual](http://people.ischool.berkeley.edu/~dbamman/DependencyManual.pdf) for more information about each tag.  Parse information is contained in the spacy token object; see the following for which attributes encode the token text, idx (position in sentence), part of speech, and dependency relation.  The syntactic head for a token is another token given in `token.head` (where all of those same token attributes are accessible)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DORmDvD6dljS",
        "outputId": "0ef85c19-6f36-4af7-9c9a-b9eefd599358",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He\t0\tPRP\tnsubj\tstarted\t3\tVBD\n",
            "started\t3\tVBD\tROOT\tstarted\t3\tVBD\n",
            "his\t11\tPRP$\tposs\tcar\t15\tNN\n",
            "car\t15\tNN\tdobj\tstarted\t3\tVBD\n",
            ".\t18\t.\tpunct\tstarted\t3\tVBD\n"
          ]
        }
      ],
      "source": [
        "test_doc = nlp(\"He started his car.\")\n",
        "for token in test_doc:\n",
        "    print(\"\\t\".join(str(x) for x in [token.text, token.idx, token.tag_, token.dep_, token.head.text, token.head.idx, token.head.tag_]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9AS8IOBdljT"
      },
      "source": [
        "**Q1**. Find the verbs that men are more characteristically the *subject* of than women.  Feel free to only consider subjects that are \"he\" and \"she\" pronouns.  This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"he\" (`he_counter`) and \"she\" (`she_counter`) as its syntactic subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "V-f82SpWdljT"
      },
      "outputs": [],
      "source": [
        "def count_subjects(tokens):\n",
        "    he_counter = Counter()\n",
        "    she_counter = Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        if token.lemma_ == 'he':\n",
        "            for verb in token.head.children:\n",
        "                if verb.dep_ == 'nsubj' and verb.head.pos_ == 'VERB':\n",
        "                    verb_lemma = verb.head.lemma_\n",
        "                    he_counter[verb_lemma] += 1\n",
        "        elif token.lemma_ == 'she':\n",
        "            for verb in token.head.children:\n",
        "                if verb.dep_ == 'nsubj' and verb.head.pos_ == 'VERB':\n",
        "                    verb_lemma = verb.head.lemma_\n",
        "                    she_counter[verb_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "06FTwdZodljT",
        "outputId": "91f66baf-7c79-47f5-d626-e83e37d98bca",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "8.634\tcome\n",
            "5.232\treply\n",
            "4.589\tsay\n",
            "4.247\tseem\n",
            "4.010\ttalk\n",
            "3.716\tdo\n",
            "3.458\tmean\n",
            "3.374\tcontinue\n",
            "3.030\ttake\n",
            "2.912\tbeg\n",
            "\n",
            "Most category 2:\n",
            "-8.431\tfeel\n",
            "-4.644\thear\n",
            "-3.175\tthink\n",
            "-2.892\tresolve\n",
            "-2.792\tfear\n",
            "-2.753\texpect\n",
            "-2.729\tcry\n",
            "-2.683\tfind\n",
            "-2.552\tstrike\n",
            "-2.514\tsee\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_subjects(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WCoKEwQdljT"
      },
      "source": [
        "**Q2**. Find the verbs that men are more characteristically the *object* of than women.  Feel free to only consider objects that are \"him\" and \"her\" pronouns.  This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"him\" (`he_counter`) and \"her\" (`she_counter`) as its syntactic direct object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "_P4VwJPGdljT"
      },
      "outputs": [],
      "source": [
        "def count_objects(tokens):\n",
        "    he_counter=Counter()\n",
        "    she_counter=Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        # We are only interested in direct-object relations\n",
        "        if token.dep_ == \"dobj\":\n",
        "            # The pronoun that is the object\n",
        "            obj_text = token.text.lower()\n",
        "\n",
        "            # The verb that governs this object\n",
        "            verb = token.head\n",
        "            # Make sure the head really is a verb (safety check)\n",
        "            if verb.pos_ != \"VERB\":\n",
        "                continue\n",
        "\n",
        "            verb_lemma = verb.lemma_.lower()   # use lemmatised form for consistency\n",
        "\n",
        "            if obj_text == \"him\":\n",
        "                he_counter[verb_lemma] += 1\n",
        "            elif obj_text == \"her\":\n",
        "                she_counter[verb_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "hIW8zRP2dljT",
        "scrolled": true,
        "outputId": "9c1d2247-5048-4e29-ad94-3671bcc98c67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "5.309\tsee\n",
            "4.798\tlike\n",
            "3.145\tknow\n",
            "2.790\twish\n",
            "2.570\tintroduce\n",
            "2.454\tsend\n",
            "2.333\tbelieve\n",
            "2.322\tsuspect\n",
            "2.175\trecommend\n",
            "2.018\tdislike\n",
            "\n",
            "Most category 2:\n",
            "-3.500\tleave\n",
            "-2.794\tattend\n",
            "-2.546\tplease\n",
            "-2.317\tstrike\n",
            "-2.182\tprevent\n",
            "-2.075\toblige\n",
            "-2.068\tsupport\n",
            "-2.032\tescape\n",
            "-2.032\ttreat\n",
            "-1.968\tamuse\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_objects(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvkOo1ymdljU"
      },
      "source": [
        "**Q3**. Find the objects that are *possessed* more frequently by men than women. Feel free to only consider possessors that are \"his\" and \"her\" pronouns.   This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given term is possessed by \"he\" (`he_counter`) and \"she\" (`she_counter`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "y4cIrhFFdljU"
      },
      "outputs": [],
      "source": [
        "def count_possessions(tokens):\n",
        "    he_counter  = Counter()\n",
        "    she_counter = Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        # Look for \"his\" or \"her\" as a possessive determiner (dep_ == \"poss\")\n",
        "        if token.dep_ == \"poss\" and token.text.lower() in [\"his\", \"her\"]:\n",
        "            # The possessed noun is the head of this token\n",
        "            possessed_noun = token.head\n",
        "            if possessed_noun.pos_ == \"NOUN\":\n",
        "                noun_lemma = possessed_noun.lemma_.lower()\n",
        "                if token.text.lower() == \"his\":\n",
        "                    he_counter[noun_lemma] += 1\n",
        "                elif token.text.lower() == \"her\":\n",
        "                    she_counter[noun_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "hxhK_F1ZdljU",
        "outputId": "5e65e204-8f72-40bf-b27a-73532a123edf",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "4.569\tmanner\n",
            "4.351\thouse\n",
            "4.291\treturn\n",
            "4.090\tname\n",
            "3.890\tattachment\n",
            "3.823\thorse\n",
            "3.745\taddress\n",
            "3.610\tprofession\n",
            "3.523\tbehaviour\n",
            "3.461\tson\n",
            "\n",
            "Most category 2:\n",
            "-7.223\tmother\n",
            "-4.576\taunt\n",
            "-4.056\tuncle\n",
            "-3.909\tsister\n",
            "-3.882\tspirit\n",
            "-3.835\teye\n",
            "-3.580\troom\n",
            "-3.504\theart\n",
            "-3.102\tbrother\n",
            "-3.046\tthought\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_possessions(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLU0UpOzdljU"
      },
      "source": [
        "**Q4**. Find the actions that are men do *to women* more frequently than women do *to men*.  Feel free to only consider subjects and objects that are \"she\"/\"he\"/\"her\"/\"him\" pronouns.   This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"he\" as the subject and \"her\" as the object (`he_counter`) and \"she\" as the subject and \"him\" as the object (`she_counter`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {
        "id": "dTn1A8WgdljU"
      },
      "outputs": [],
      "source": [
        "def count_SVO_tuples(tokens):\n",
        "    he_counter  = Counter()  # verb: \"he\" (subj) → \"her\" (obj)\n",
        "    she_counter = Counter()  # verb: \"she\" (subj) → \"him\" (obj)\n",
        "\n",
        "    for token in tokens:\n",
        "        # Look for verbs (we'll check subject and object children)\n",
        "        if token.pos_ == \"VERB\":\n",
        "            verb_lemma = token.lemma_.lower()\n",
        "\n",
        "            # Find subject and object among children\n",
        "            subject = None\n",
        "            object_ = None\n",
        "\n",
        "            for child in token.children:\n",
        "                if child.dep_ in (\"nsubj\", \"nsubjpass\"):  # nominal subject\n",
        "                    subject = child\n",
        "                elif child.dep_ == \"dobj\":                # direct object\n",
        "                    object_ = child\n",
        "\n",
        "            # Only proceed if we have both subject and object\n",
        "            if subject and object_:\n",
        "                subj_text = subject.text.lower()\n",
        "                obj_text  = object_.text.lower()\n",
        "\n",
        "                # Case 1: he → her\n",
        "                if subj_text == \"he\" and obj_text == \"her\":\n",
        "                    he_counter[verb_lemma] += 1\n",
        "                # Case 2: she → him\n",
        "                elif subj_text == \"she\" and obj_text == \"him\":\n",
        "                    she_counter[verb_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "QozyJ4eDdljV",
        "outputId": "7408aa81-411f-40b3-8860-391f44c7e58e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "2.779\ttell\n",
            "2.089\tleave\n",
            "1.340\thear\n",
            "1.340\tjoin\n",
            "1.229\tgive\n",
            "1.075\tassure\n",
            "1.043\tforget\n",
            "1.043\taddress\n",
            "0.923\task\n",
            "0.885\tlove\n",
            "\n",
            "Most category 2:\n",
            "-3.095\tsee\n",
            "-1.593\thave\n",
            "-1.166\tentreat\n",
            "-0.997\tknow\n",
            "-0.875\twish\n",
            "-0.875\tunderstand\n",
            "-0.875\twatch\n",
            "-0.714\tlike\n",
            "-0.663\taccept\n",
            "-0.633\trefuse\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_SVO_tuples(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anguaii5YpcX"
      },
      "source": [
        "**Q5**. **In a few sentences,** reflect on the analysis you did above. What claims can you make about the data? What are some limitations?"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UAkhkBSYpcY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}