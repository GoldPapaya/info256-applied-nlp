{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/GoldPapaya/info256-applied-nlp/blob/main/11.nlp/HW10_SyntacticRelations.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZiz11AmYpcP"
      },
      "source": [
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/dbamman/anlp25/blob/main/11.nlp/HW10_SyntacticRelations.ipynb)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LRYkjH_3dljL"
      },
      "source": [
        "# HW10: Exploring gender in books\n",
        "\n",
        "This notebook explores dependency parsing by identifying the actions and objects that are characteristically associated with characters as a function of their referential gender (\"he\"/\"she\")."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "m4OX0TrLdljO"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import operator\n",
        "\n",
        "from collections import Counter\n",
        "\n",
        "import spacy\n",
        "from tqdm import tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "8Iv37AaPdljQ"
      },
      "outputs": [],
      "source": [
        "nlp = spacy.load('en_core_web_sm')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mLC5EUZ9YpcR"
      },
      "source": [
        "## Load data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l5CKftUPdljQ"
      },
      "source": [
        "We'll run seven novels by Jane Austen through spaCy (this will take a few minutes)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uBFrBn1wd2wj",
        "outputId": "690b70ff-30ef-4581-eb59-9f4d4c5b2f7f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-11-09 18:10:20--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/emma.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 927445 (906K) [text/plain]\n",
            "Saving to: ‘emma.txt’\n",
            "\n",
            "emma.txt            100%[===================>] 905.71K  5.35MB/s    in 0.2s    \n",
            "\n",
            "2025-11-09 18:10:20 (5.35 MB/s) - ‘emma.txt’ saved [927445/927445]\n",
            "\n",
            "--2025-11-09 18:10:20--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/lady_susan.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 149538 (146K) [text/plain]\n",
            "Saving to: ‘lady_susan.txt’\n",
            "\n",
            "lady_susan.txt      100%[===================>] 146.03K  --.-KB/s    in 0.08s   \n",
            "\n",
            "2025-11-09 18:10:21 (1.78 MB/s) - ‘lady_susan.txt’ saved [149538/149538]\n",
            "\n",
            "--2025-11-09 18:10:21--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/mansfield_park.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 925067 (903K) [text/plain]\n",
            "Saving to: ‘mansfield_park.txt’\n",
            "\n",
            "mansfield_park.txt  100%[===================>] 903.39K  4.59MB/s    in 0.2s    \n",
            "\n",
            "2025-11-09 18:10:22 (4.59 MB/s) - ‘mansfield_park.txt’ saved [925067/925067]\n",
            "\n",
            "--2025-11-09 18:10:22--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/northanger_abbey.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 465393 (454K) [text/plain]\n",
            "Saving to: ‘northanger_abbey.txt’\n",
            "\n",
            "northanger_abbey.tx 100%[===================>] 454.49K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-09 18:10:22 (3.45 MB/s) - ‘northanger_abbey.txt’ saved [465393/465393]\n",
            "\n",
            "--2025-11-09 18:10:22--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/persuasion.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.109.133, 185.199.108.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.109.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 494990 (483K) [text/plain]\n",
            "Saving to: ‘persuasion.txt’\n",
            "\n",
            "persuasion.txt      100%[===================>] 483.39K  --.-KB/s    in 0.1s    \n",
            "\n",
            "2025-11-09 18:10:23 (3.61 MB/s) - ‘persuasion.txt’ saved [494990/494990]\n",
            "\n",
            "--2025-11-09 18:10:23--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/pride.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 704832 (688K) [text/plain]\n",
            "Saving to: ‘pride.txt’\n",
            "\n",
            "pride.txt           100%[===================>] 688.31K  4.33MB/s    in 0.2s    \n",
            "\n",
            "2025-11-09 18:10:24 (4.33 MB/s) - ‘pride.txt’ saved [704832/704832]\n",
            "\n",
            "--2025-11-09 18:10:24--  https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/sense_and_sensibility.txt\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 706124 (690K) [text/plain]\n",
            "Saving to: ‘sense_and_sensibility.txt’\n",
            "\n",
            "sense_and_sensibili 100%[===================>] 689.57K  4.32MB/s    in 0.2s    \n",
            "\n",
            "2025-11-09 18:10:25 (4.32 MB/s) - ‘sense_and_sensibility.txt’ saved [706124/706124]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/emma.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/lady_susan.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/mansfield_park.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/northanger_abbey.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/persuasion.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/pride.txt\n",
        "!wget https://raw.githubusercontent.com/dbamman/anlp25/refs/heads/main/data/fiction/sense_and_sensibility.txt"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "nyq6Xhx6dljQ",
        "outputId": "edd41e0b-96ef-49cb-c3ce-b97fa10035fb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7/7 [03:01<00:00, 25.91s/it]\n"
          ]
        }
      ],
      "source": [
        "files = [\"emma.txt\", \"lady_susan.txt\", \"mansfield_park.txt\", \"northanger_abbey.txt\", \"persuasion.txt\", \"pride.txt\", \"sense_and_sensibility.txt\"]\n",
        "\n",
        "def read_all_files(filenames):\n",
        "    all_tokens = []\n",
        "\n",
        "    for filename in tqdm(filenames):\n",
        "        data = open(filename, encoding=\"utf-8\").read()\n",
        "        tokens = nlp(data)\n",
        "        all_tokens.extend(tokens)\n",
        "    return all_tokens\n",
        "\n",
        "all_tokens = read_all_files(files)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "MOIwxtVydljR",
        "outputId": "190f788f-2510-449a-9061-f6057b061172",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "972810\n"
          ]
        }
      ],
      "source": [
        "print(len(all_tokens))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KJHqhcmoYpcT"
      },
      "source": [
        "## Setting up log odds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "FmCkFJy6dljR"
      },
      "outputs": [],
      "source": [
        "def logodds(counter1, counter2, display=25):\n",
        "    \"\"\"\n",
        "    Function that takes two Counter objects as inputs and prints out a ranked list of terms\n",
        "    more characteristic of the first counter than the second.  Here we'll use log-odds\n",
        "    with an uninformative prior (from Monroe et al 2008, \"Fightin Words\", eqn. 22) as our metric.\n",
        "\n",
        "    \"Category 1\" corresponds to the category of the counter1 object (the first argument)\n",
        "    \"Category 2\" corresponds to the category of the counter2 object (the second argument)\n",
        "    \"\"\"\n",
        "    vocab=dict(counter1)\n",
        "    vocab.update(dict(counter2))\n",
        "    count1_sum=sum(counter1.values())\n",
        "    count2_sum=sum(counter2.values())\n",
        "\n",
        "    ranks={}\n",
        "    alpha=0.01\n",
        "    alphaV=len(vocab)*alpha\n",
        "\n",
        "    for word in vocab:\n",
        "\n",
        "        log_odds_ratio=math.log( (counter1[word] + alpha) / (count1_sum+alphaV-counter1[word]-alpha) ) - math.log( (counter2[word] + alpha) / (count2_sum+alphaV-counter2[word]-alpha) )\n",
        "        variance=1./(counter1[word] + alpha) + 1./(counter2[word] + alpha)\n",
        "\n",
        "        ranks[word]=log_odds_ratio/math.sqrt(variance)\n",
        "\n",
        "    sorted_x = sorted(ranks.items(), key=operator.itemgetter(1), reverse=True)\n",
        "\n",
        "    print(\"Most category 1:\")\n",
        "    for k,v in sorted_x[:display]:\n",
        "        print(\"%.3f\\t%s\" % (v,k))\n",
        "\n",
        "    print(\"\\nMost category 2:\")\n",
        "    for k,v in reversed(sorted_x[-display:]):\n",
        "        print(\"%.3f\\t%s\" % (v,k))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dhvQ2pEMYpcU"
      },
      "source": [
        "## Dependency parsing with SpaCy"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "njbslDssdljS"
      },
      "source": [
        "SpaCy uses the [ClearNLP dependency labels](https://github.com/clir/clearnlp-guidelines/blob/master/md/specifications/dependency_labels.md), which are very close to the Stanford typed dependencies.  See the [Stanford dependencies manual](http://people.ischool.berkeley.edu/~dbamman/DependencyManual.pdf) for more information about each tag.  Parse information is contained in the spacy token object; see the following for which attributes encode the token text, idx (position in sentence), part of speech, and dependency relation.  The syntactic head for a token is another token given in `token.head` (where all of those same token attributes are accessible)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "DORmDvD6dljS",
        "outputId": "92517fbd-4c6b-4fe7-8e76-e54cb17ae622",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "He\t0\tPRP\tnsubj\tstarted\t3\tVBD\n",
            "started\t3\tVBD\tROOT\tstarted\t3\tVBD\n",
            "his\t11\tPRP$\tposs\tcar\t15\tNN\n",
            "car\t15\tNN\tdobj\tstarted\t3\tVBD\n",
            ".\t18\t.\tpunct\tstarted\t3\tVBD\n"
          ]
        }
      ],
      "source": [
        "test_doc = nlp(\"He started his car.\")\n",
        "for token in test_doc:\n",
        "    print(\"\\t\".join(str(x) for x in [token.text, token.idx, token.tag_, token.dep_, token.head.text, token.head.idx, token.head.tag_]))\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9AS8IOBdljT"
      },
      "source": [
        "**Q1**. Find the verbs that men are more characteristically the *subject* of than women.  Feel free to only consider subjects that are \"he\" and \"she\" pronouns.  This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"he\" (`he_counter`) and \"she\" (`she_counter`) as its syntactic subject."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "V-f82SpWdljT"
      },
      "outputs": [],
      "source": [
        "def count_subjects(tokens):\n",
        "    he_counter = Counter()\n",
        "    she_counter = Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        if token.lemma_ == 'he':\n",
        "            for verb in token.head.children:\n",
        "                if verb.head.pos_ == 'VERB' and verb.dep_ == 'nsubj':\n",
        "                    verb_lemma = verb.head.lemma_\n",
        "                    he_counter[verb_lemma] += 1\n",
        "        elif token.lemma_ == 'she':\n",
        "            for verb in token.head.children:\n",
        "                if verb.head.pos_ == 'VERB' and verb.dep_ == 'nsubj':\n",
        "                    verb_lemma = verb.head.lemma_\n",
        "                    she_counter[verb_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "06FTwdZodljT",
        "outputId": "869f2545-1417-4879-c5c6-8030ccc5ecc8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "8.634\tcome\n",
            "5.232\treply\n",
            "4.589\tsay\n",
            "4.247\tseem\n",
            "4.010\ttalk\n",
            "3.716\tdo\n",
            "3.458\tmean\n",
            "3.374\tcontinue\n",
            "3.030\ttake\n",
            "2.912\tbeg\n",
            "\n",
            "Most category 2:\n",
            "-8.431\tfeel\n",
            "-4.644\thear\n",
            "-3.175\tthink\n",
            "-2.892\tresolve\n",
            "-2.792\tfear\n",
            "-2.753\texpect\n",
            "-2.729\tcry\n",
            "-2.683\tfind\n",
            "-2.552\tstrike\n",
            "-2.514\tsee\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_subjects(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8WCoKEwQdljT"
      },
      "source": [
        "**Q2**. Find the verbs that men are more characteristically the *object* of than women.  Feel free to only consider objects that are \"him\" and \"her\" pronouns.  This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"him\" (`he_counter`) and \"her\" (`she_counter`) as its syntactic direct object."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "_P4VwJPGdljT"
      },
      "outputs": [],
      "source": [
        "def count_objects(tokens):\n",
        "    he_counter=Counter()\n",
        "    she_counter=Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        if token.dep_ == 'dobj':\n",
        "            verb = token.head\n",
        "            if verb.pos_ != 'VERB':\n",
        "                continue\n",
        "            obj_text = token.text.lower()\n",
        "            verb_lemma = verb.lemma_.lower()\n",
        "\n",
        "            if obj_text == 'him':\n",
        "                he_counter[verb.lemma_] += 1\n",
        "            elif obj_text == 'her':\n",
        "                she_counter[verb.lemma_] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "id": "hIW8zRP2dljT",
        "scrolled": true,
        "outputId": "f50911f8-89b0-415c-96be-5871679ac204",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "5.309\tsee\n",
            "4.798\tlike\n",
            "3.145\tknow\n",
            "2.790\twish\n",
            "2.570\tintroduce\n",
            "2.454\tsend\n",
            "2.333\tbelieve\n",
            "2.322\tsuspect\n",
            "2.175\trecommend\n",
            "2.018\tdislike\n",
            "\n",
            "Most category 2:\n",
            "-3.500\tleave\n",
            "-2.794\tattend\n",
            "-2.546\tplease\n",
            "-2.317\tstrike\n",
            "-2.182\tprevent\n",
            "-2.075\toblige\n",
            "-2.068\tsupport\n",
            "-2.032\tescape\n",
            "-2.032\ttreat\n",
            "-1.968\tamuse\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_objects(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vvkOo1ymdljU"
      },
      "source": [
        "**Q3**. Find the objects that are *possessed* more frequently by men than women. Feel free to only consider possessors that are \"his\" and \"her\" pronouns.   This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given term is possessed by \"he\" (`he_counter`) and \"she\" (`she_counter`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "y4cIrhFFdljU"
      },
      "outputs": [],
      "source": [
        "def count_possessions(tokens):\n",
        "    he_counter  = Counter()\n",
        "    she_counter = Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        obj_text = token.text.lower()\n",
        "        if token.dep_ == 'poss' and obj_text in ['his', 'her']:\n",
        "            possessed_noun = token.head\n",
        "            if possessed_noun.pos_ == 'NOUN':\n",
        "                noun_lemma = possessed_noun.lemma_.lower()\n",
        "                if obj_text == 'his':\n",
        "                    he_counter[noun_lemma] += 1\n",
        "                elif obj_text == 'her':\n",
        "                    she_counter[noun_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "hxhK_F1ZdljU",
        "outputId": "840cfd0f-5b52-4690-8243-8f175dfcbe67",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "4.569\tmanner\n",
            "4.351\thouse\n",
            "4.291\treturn\n",
            "4.090\tname\n",
            "3.890\tattachment\n",
            "3.823\thorse\n",
            "3.745\taddress\n",
            "3.610\tprofession\n",
            "3.523\tbehaviour\n",
            "3.461\tson\n",
            "\n",
            "Most category 2:\n",
            "-7.223\tmother\n",
            "-4.576\taunt\n",
            "-4.056\tuncle\n",
            "-3.909\tsister\n",
            "-3.882\tspirit\n",
            "-3.835\teye\n",
            "-3.580\troom\n",
            "-3.504\theart\n",
            "-3.102\tbrother\n",
            "-3.046\tthought\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_possessions(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FLU0UpOzdljU"
      },
      "source": [
        "**Q4**. Find the actions that are men do *to women* more frequently than women do *to men*.  Feel free to only consider subjects and objects that are \"she\"/\"he\"/\"her\"/\"him\" pronouns.   This function should return two Counter objects (`he_counter` and `she_counter`) which counts the number of times a given verb has \"he\" as the subject and \"her\" as the object (`he_counter`) and \"she\" as the subject and \"him\" as the object (`she_counter`)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "dTn1A8WgdljU"
      },
      "outputs": [],
      "source": [
        "def count_SVO_tuples(tokens):\n",
        "    he_counter  = Counter()\n",
        "    she_counter = Counter()\n",
        "\n",
        "    for token in tokens:\n",
        "        if token.pos_ == 'VERB':\n",
        "            verb_lemma = token.lemma_.lower()\n",
        "\n",
        "            subj = None\n",
        "            obj = None\n",
        "            for child in token.children:\n",
        "                if child.dep_ in ['nsubj', 'nsubjpass']:\n",
        "                    subj = child\n",
        "                elif child.dep_ == 'dobj':\n",
        "                    obj = child\n",
        "\n",
        "            if subj and obj:\n",
        "                subj_text = subj.text.lower()\n",
        "                obj_text  = obj.text.lower()\n",
        "                if subj_text == 'he' and obj_text == 'her':\n",
        "                    he_counter[verb_lemma] += 1\n",
        "                elif subj_text == 'she' and obj_text == 'him':\n",
        "                    she_counter[verb_lemma] += 1\n",
        "\n",
        "    return he_counter, she_counter"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "metadata": {
        "id": "QozyJ4eDdljV",
        "outputId": "37196015-adf7-40ea-f1a4-60501042401f",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Most category 1:\n",
            "2.779\ttell\n",
            "2.089\tleave\n",
            "1.340\thear\n",
            "1.340\tjoin\n",
            "1.229\tgive\n",
            "1.075\tassure\n",
            "1.043\tforget\n",
            "1.043\taddress\n",
            "0.923\task\n",
            "0.885\tlove\n",
            "\n",
            "Most category 2:\n",
            "-3.095\tsee\n",
            "-1.593\thave\n",
            "-1.166\tentreat\n",
            "-0.997\tknow\n",
            "-0.875\twish\n",
            "-0.875\tunderstand\n",
            "-0.875\twatch\n",
            "-0.714\tlike\n",
            "-0.663\taccept\n",
            "-0.633\trefuse\n"
          ]
        }
      ],
      "source": [
        "he_counts, she_counts = count_SVO_tuples(all_tokens)\n",
        "logodds(he_counts, she_counts, display=10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "anguaii5YpcX"
      },
      "source": [
        "**Q5**. **In a few sentences,** reflect on the analysis you did above. What claims can you make about the data? What are some limitations?"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Across all analyses above, we see that there is a very clear difference in when terms are applied with reference to gender labels. It is also clear from the results that category 1 and 2 tend to follow certain themes in each case. For example, in the first analysis, we see that terms associated with 'he' tend to involve some form of speaking or doing. With 'she' the terms broadly embody emotion and sensory. With these analyses, we can find these relationships in the language used, and can claim that terms used in the text are not applied evenly for both 'he' and 'she'. A limitation, however, could be that the text is simply missing several cases where, for example, a term is possessed by one gender over another. In such a case, it is possible to have lots of data for one category, but very little for the other, impacting the validity of the results."
      ],
      "metadata": {
        "id": "EeBv4yYq5VTI"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_UAkhkBSYpcY"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.14"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}